<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Modelo del Perceptrón</title>
    <style>
        body {
            font-family: Arial, Helvetica, sans-serif;
            line-height: 1.6;
            margin: 40px;
            background-color: #f8f9fa;
            color: #222;
        }
        h1, h2 {
            color: #2c3e50;
        }
        section {
            margin-bottom: 20px;
            padding: 15px;
            background-color: #fff;
            border-radius: 10px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        pre {
            background: #f4f4f4;
            padding: 10px;
            border-radius: 5px;
            overflow-x: auto;
        }
    </style>
</head>
<body>
    <h1>Modelo del Perceptrón</h1>

    <section>
        <h2>1. Qué es y cómo está hecho</h2>
        <p>El perceptrón es el modelo más básico de una neurona artificial, creado por Frank Rosenblatt en 1958. Su arquitectura se basa en tres componentes esenciales: las <strong>entradas</strong>, los <strong>pesos</strong> y la <strong>función de activación</strong>.</p>

        <ul>
            <li><strong>Entradas (x):</strong> son los datos o variables de entrada del modelo. Cada una representa una característica o atributo del problema a analizar.</li>
            <li><strong>Pesos (w):</strong> indican la importancia de cada entrada. El modelo ajusta estos valores durante el entrenamiento para mejorar su precisión.</li>
            <li><strong>Función de activación:</strong> decide si la neurona se “activa” o no, dependiendo del resultado de la suma ponderada de las entradas. En el perceptrón clásico, se usa la función escalón, que devuelve 1 si el valor supera un umbral y 0 en caso contrario.</li>
        </ul>

        <pre>// Fórmula básica
z = Σ (w_i * x_i) + b
y = step(z)  // y ∈ &#123;0, 1&#125;</pre>
    </section>

    <section>
        <h2>2. Por qué es importante</h2>
        <p>El perceptrón fue la primera implementación funcional de una red neuronal. Aunque solo puede resolver problemas de clasificación lineal (como separar dos grupos de puntos en un plano), su diseño sentó las bases de las redes neuronales modernas.</p>
        <p>Su importancia radica en que introdujo la idea del <strong>aprendizaje automático mediante ajuste de pesos</strong>, el concepto de <strong>función de activación</strong> y la posibilidad de construir <strong>modelos compuestos</strong> al conectar varias neuronas en capas, lo que dio origen al perceptrón multicapa (MLP) y, posteriormente, a las redes neuronales profundas (Deep Learning).</p>
    </section>

    <section>
        <h2>3. Ejemplos de uso en clasificación binaria</h2>

        <h3>a) Clasificación de correos electrónicos (spam o no spam)</h3>
        <p>Se entrenó un perceptrón con características como frecuencia de palabras, presencia de enlaces o longitud del mensaje. La salida binaria era 1 (spam) o 0 (no spam).</p>

        <h3>b) Reconocimiento de dígitos simples</h3>
        <p>Antes del uso de redes convolucionales, los perceptrones simples se empleaban para distinguir entre dígitos binarios (por ejemplo, 0 y 1) usando imágenes reducidas en píxeles.</p>

        <h3>c) Clasificación de sentimientos</h3>
        <p>En tareas básicas de análisis de texto, un perceptrón podía clasificar frases como positivas o negativas según la presencia de palabras clave asociadas a emociones.</p>

        <p>Estos ejemplos muestran cómo el perceptrón permitió transformar datos normales en decisiones binarias útiles, marcando el inicio del aprendizaje automático moderno.</p>
    </section>
</body>
</html>
